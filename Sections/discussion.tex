\section{There and back again: towards systematic quantification of natural behavior}

Understanding how living organisms (humans included), interact with and react to the environments they are exposed to has captured scientific curiosity since antiquity. As introduced in chapter \ref{chap:introduction}, modern science has come a long way since then, and a plethora of approaches have been proposed, from observational ethological studies to extremely reductionist and question-specific settings.

The advent of machine-learning-based tracking and quantification approaches is particularly exciting because it evolves in a way that is applicable across the entire board. First off, automatic quantification methods pose a unique opportunity to systematize observational studies in the wild in non-invasive ways, even without human presence. This can have tremendous impact not only in our understanding of ethology itself, but also pave the way for innovations in ecology and wildlife conservation.

Along these lines and starting broad, the current rapid decline of animal diversity (genetic, ecological, and behavioral) underscores the urgent need for tools that can conduct swift and comprehensive assessments of wildlife diversity and population dynamics \cite{Ceballos2020VertebratesExtinction}. Traditional data collection methods, which rely heavily on human fieldwork, present numerous challenges including time and cost, potential threats to wildlife and human safety, and the inevitable generation of biased datasets. These limitations significantly hinder our understanding of global ecological dynamics and the effectiveness of our conservation efforts.

However dismal the landscape may look, technological advancements show some light at the end of the tunnel. Alongside hardware breakthroughs, such as trap or on-animal cameras and automatic drones, the advancements in freely available markerless pose estimation tools presented earlier in this thesis can help in a number of ways, such as individual identification, detection of migration patterns with static sensors, injury detection, and quantification of social dynamics in the wild, to name a few \cite{Tuia2022PerspectivesConservation}.

The potential of these technologies to enhance our understanding of animal ecology, streamline conservation efforts, and even illuminate new paths for wildlife preservation is enormous. The promise they hold, coupled with their integration with machine learning, could play a significant role in turning the tide on the alarming decline in animal diversity.

Moreover, the current thesis is an example of how the opposite trend can be executed: instead of relying on artificially simplistic models that enable simple quantification in laboratory settings, richer environments can be put in place without sacrificing rigor, by leveraging markerless pose estimation and automated quantification methods.

Thus and so, and after exploring the state of the art in chapter \ref{chap:sota}, chapters \ref{chap:methods} and \ref{chap:joss} introduced a novel open-source tool, called DeepOF, capable of examining both individual and social behavioral patterns in rodents using data annotated through DeepLabCut pose estimation, in supervised and unsupervised ways. Furthermore, chapter \ref{chap:natcomm} delved into how, by applying this tool, we characterized unique individual and social behavioral profiles following CSDS, identified through traits annotated by DeepOF on C57Bl/6N subjects. Also, comparable results were obtained with our unsupervised pipeline, capable of recognizing behavioral shifts across various experimental contexts, including social interaction, single-animal open field tests, and social avoidance tasks. Furthermore, by exploring behavioral dynamics, DeepOF allowed us to systematically pinpoint how the initial moments of interaction with a new same-species partner are crucial for the social profiling of CSDS exposure in both supervised and unsupervised pipelines.

In this final chapter, we will delve into the impact that our tool can represent on the field it is immersed in, both in terms of technology development and knowledge discovery.

\section[DeepOF in context]{DeepOF in context: the current landscape of open-source software for behavioral analysis}

The release of DeepLabCut in 2018 was arguably the cornerstone of a methodological revolution in the field of behavioral neuroscience. Since then, a plethora of tools have enabled researchers not only to quickly automate previously laborious manual quantification, but to think outside the box and design more complex and naturalistic new experimental settings altogether. While empowering, the current software landscape has quickly become little short of daunting: packages for pose estimation itself \cite{Mathis2018DeepLabCut:Learning, Pereira2022SLEAP:Tracking}, supervised annotation \cite{Ro2020SimpleAnimals, Schweihoff2022A-SOiDBehavior}, unsupervised analysis \cite{Hsu2021B-SOiDBehaviors, Weinreb2023Keypoint-MoSeq:Dynamics, Luxem2022IdentifyingMotion}, and so on, propose constant innovation in a field that is still to stabilize to a new status quo, in a rapid turnover fashion that mimics the current state of other AI-dependent scenarios \cite{Shao2022TracingTrends}.
In this context, DeepOF offers the (to date) unique advantage of being an easy-to-use, label-free exploratory tool capable of annotating and analyzing motion-tracking data with just a few well-documented commands. This makes it easy for new users to adopt and try the software without big commitments, which we believe is key to success in such a rapidly changing field. Moreover, far from being a mere compilation of previously established methods, most algorithms presented are custom and adapted specifically to the tasks they are deployed to be used for. This way, easy adoption is contrasted with choice and customization, if a given user desires to take advantage of it. DeepOF is not designed to beat other available modules in their own game, but rather to act as a complement: after running an unsupervised pipeline and obtaining results that hint at particular (although non-pure) behaviors, a researcher could use the acquired knowledge to label and train supervised models using a tool like SimBA \cite{Ro2020SimpleAnimals}, for example, in order to confirm their suspicions.

Moreover, a significant advantage of DeepOF, SimBA \cite{Ro2020SimpleAnimals}, VAME \cite{Luxem2022IdentifyingMotion}, and many of the tools mentioned in this thesis is their open-source nature. Besides increasing transparency, which is always key to reproducibility, one must not forget that all these packages are being developed by (and mostly for) non-profit research organizations that thrive by interacting, debugging, and building on top of each other. This sort of synergetic, interdependent competition is a core aspect of modern science, and having access to code (including models, training schemes, and data) is crucial. Furthermore, a side effect of the overwhelming adoption of motion tracking software such as DeepLabCut is the increasing number of public datasets that are being released, which in turn enable not only the training of more powerful architectures that need less supervision \cite{Ye2022SuperAnimalBehavior}, but also the creation of open-source competitions and benchmarks. The Caltech Mouse Social Interactions (CalMS21) dataset, for example, is a pioneer in providing benchmarks for the detection of social interactions, annotation style transfer, and identification of rare traits \cite{Caltech2021TheInteractions}. Although unsupervised learning benchmarking is largely uncharted territory so far, it will be crucial to compare the DeepOF pipeline with other available methods in this area as the tools become accessible. Finally, although requiring specific hardware in many cases, such as increasingly powerful GPUs, all mentioned software is free to use, which makes it broadly accessible for research groups with limited resources. This is a huge advantage over the proprietary, often expensive, previous state-of-the-art \cite{ANY-maze}.

Moreover, several extremely recent developments introduced significant progress on foundation models for markerless, one-shot video tracking. Efforts such as TAPIR (\textit{Tracking Any Point with per-frame Initialization and temporal Refinement
}, from \textit{DeepMind}) \cite{DoerschTAPIR:Refinement} and \textit{OmniMotion} \cite{WangTrackingOnce} allow users to track any point in a given video upon labelling a single frame. While integration attempts into DeepOF have shown that tracking accuracy is yet to match DeepLabCut and other neuroscience-oriented programs, ease of use could lead to massive adoption of these pipelines as soon as models get better, with efforts in fine-tuning these general-purpose pretrained models to more specific tasks probably playing a big role in the near future.

A word of caution should be stated, however, since these models (as many others) have also increasing malicious potential if falling into the wrong hands: lightweight, powerful models for tracking and identifying individuals could be used for illegal surveillance, for example. As is currently the case in other fields, such as large language models (LLMs) \cite{Weidinger2021EthicalModels, Weidinger2022TaxonomyModels}, I believe ethical considerations need to be thoroughly taken into account when open-sourcing, especially as datasets become larger and models more capable and easier to tune.

\section{Perspectives on supervised learning on behavioral data}

Going back to the supervised pipeline provided within DeepOF, we should highlight that it offers a set of rule-based annotators and pre-trained models that free the user from the need to manually label their data. While convenient and easy to use, this approach is extremely limited to simple behaviors that can be either reduced to simple but stable rules (such as nose-to-nose contacts or climbing behaviors) or robustly generalizable across datasets (such as the huddle classifier presented in chapter \ref{chap:natcomm}).
With the increasing popularity of these tools in the research community and the aforementioned rapidly growing corpus of datasets and related competitions, it is to be expected that more complex traits will achieve similar transfer learning results in the near future. This would dramatically simplify the process of labeling and detecting specific, pre-defined behaviors, potentially eliminating the need for training new models altogether, in a fashion that would resemble the current discussion on foundation models \cite{Bommasani2021OnModels}. 

Furthermore, the current developments in Large Language Models (LLMs) and text interfaces for image processing and generation \cite{OpenAI2023GPT-4Report, Ramesh2022HierarchicalLatents} suggest that a future where describing specific, unlabeled behaviors with text to an LLM-video model capable of automatically recognizing patterns is (although far from the current state of the art) within reach, and an interesting path forward.

\section{Perspectives on unsupervised learning on behavioral data}

As introduced in chapter \ref{chap:introduction}, even if adopting a purely mechanistic definition, behavior is not inherently discrete, but arguably hierarchical. Complex actions can always be decomposed into simpler ones (typically referred to as primitives) whose repetitive nature makes them simpler to detect. Discretizing motion tracking data is therefore (as is often the case in other fields too) an ill-defined problem: with no natural solution present, a given set of clusters will focus on some aspects of behavior, leaving others behind. This renders discretization a utility problem that serves the purpose of allowing researchers to test hypotheses related to a broader scope, but which is arguably only secondary to learning robust representations.

While in DeepOF we have focused primarily on learning useful discretization models of motion, I believe future work in this direction should focus on understanding the underlying learned representations better. Along these lines, the field of representation learning has set the core principles a good and robust representation should be able to follow \cite{Le-Khac2020ContrastiveReview}. First, representations should be \textbf{expressive}, in the sense that they should be able to represent an exponential amount of configurations for their size. This would contrast, for example, with other representations such as one-hot encodings or mere hard cluster assignments. Second, good representations should be \textbf{robust} to small and local variations in input data. As an example, behavioral representations in DeepOF should vary neither with the position of the animals in the arena nor with their rotational orientation, hence these sources of variance are removed during processing. Third, good representations should be \textbf{disentangled}, meaning that learned dimensions should be uncorrelated and represent distinguishable factors with identifiable meanings. Despite not being perfect, this set of principles serves as a rule of thumb to design interpretability tests and analyses, and their usefulness in this context remains to be explored.

This type of analysis, together with the development of systematic benchmarks for unsupervised learning on motion tracking, would be an ideal framework to formally compare all the models provided within DeepOF. So far, comparisons were purely functional to choose a good default for the deployed package while exploring different variants that extended the state of the art in the field. Thus, metrics such as training time and compute resources needed, and discrimination capabilities between global animal embeddings across experimental conditions (as presented in chapter \ref{chap:natcomm}), were the main model selection criteria. The exception is the introduction of contrastive learning models, which were included in the package after the submission of the paper, and yielded comparable results with shorter training times and fewer parameters. This is exciting news moving forward and sets self-supervised alternatives as the most likely course for further immediate model development.

Thus and so, unsupervised (and self-supervised) representation learning evaluation remains, in my opinion, the most critical point for research in the immediate future. This would not only enable robust hypothesis testing and latent manipulation, but also alignment across modalities, as will be explored in the next sections.

\section{Increasing resolution in neurobiological research: behavioral quantification in context}

A living system is far more than the sum of its parts, with different biological levels interacting and regulating one another constantly in complex ways. From genetics, transcriptomics, epigenetics, and proteomics, to neural signaling, behavior, and environmental factors, being able to capture information from different biological levels in clever ways can be key to understanding any phenotype \cite{Miranda2023IncreasingBehaviors}.

Along these lines, the presented breakthroughs in motion tracking are not isolated. Recent years have seen remarkable progress in other areas relevant for neurobiological research, following a common trend of increasing experimental resolution, also outside the temporal domain \cite{Miranda2023IncreasingBehaviors}. Interestingly, in many fields other than motion tracking, breakthrough developments came mostly from the hardware side, which in turn allowed researchers to collect more data and raised the stakes of data analysis and software development in specific domains. 

As a representative example, we can explore the field of transcriptomics, where developments in single-cell resolution sequencing technologies sparked a plethora of tools and methods that innovate how data are analyzed. Here, programs like SCANPY \cite{Wolf2018SCANPY:Analysis} and SEURAT \cite{Hao2021IntegratedData} have earned recognition as the state of the art in the field, providing high-quality sets of tools, workflows, benchmarks, tutorials, and user support. They also have grown an extensive user community, which creates feedback loops with contributions and extensions which improve the software constantly. A flagrant example of such an extension is SquidPy \cite{Palla2022Squidpy:Analysis}, a package that focuses on the forefront of spatial transcriptomics,  which is greatly helping to improve our understanding of how cells in tissues are organized and interact with each other. 

All in all, this standardization offers many benefits for several connected fields (including stress research, as explored in our published commentary on STRESS \cite{Miranda2023IncreasingBehaviors}), and has a big impact not only on our basic understanding of cell makeup and gene activity in key tissues, but also on the discovery of new drug targets and development of new treatments. As a concrete example, in 2022 Lopez et al.\ used a mix of automatic behavior tracking methods and single-cell RNA-sequencing techniques to discover specific molecular patterns in different stress-related cell types, and reported a new way in which the long-lasting antidepressant effects of ketamine work in a certain type of nerve cell in a specific part of adult mice's brains \cite{Lopez2022KetamineKcnq2}. In this paper, motion tracking technology is used to automatically assess shifts in behavior across different experimental groups, illustrating how automated behavioral drug screenings can be carried out.

Moreover, transcriptomics is far from being the only case. Proteomics, for example, is being positively impacted by new developments in techniques such as mass spectrometry \cite{Mann2021ArtificialDiscovery}, and by AI-powered tools such as \textit{AlphaFold} \cite{Jumper2021HighlyAlphaFold}, which are solving biochemical problems that until a few years ago were deemed unreachable. Brain imaging and neural activity measuring are other relevant fields that have seen recent relevant advances, such as resolution improvements for functional MRI \cite{Toi2022InResolution}, and real time joint behavioral-motion capture using miniscopes and calcium sensors \cite{Dana2019High-performanceMicrocompartments, deGroot2020NinscopeInvestigations}.

As illustrated in the aforementioned paper, the combination of motion tracking quantification with many of these tools holds a lot of potential to measure the impact of genetic and biochemical changes in behavior systematically. However,  these techniques often describe different (albeit non-orthogonal) axes of the same phenomena. Although learning from and interpreting each on its own can already be useful to expand our knowledge in many ways, much information is lost in the process. 

\section{Beyond motion tracking: integrating multimodal data}

The science of learning how to better integrate these different sources of data, which can lead to a more holistic understanding of the underlying, common phenomena under study, is often referred to as \textbf{multimodal integration} (or \textbf{multimodal learning}, in the context of ML). As a side note, it is important to highlight that behavior itself is more than motion alone, and adopting a broad definition would require integrating additional variables that cannot (at least to date) be extracted from video. These include, for example, things like heart rate, respiratory rate, vocalization, and neural activity.

At a basic level, multimodal integration thus requires researchers to  draw conclusions from experiments describing multiple (complementary) axes of the same problem and drawing conclusions explaining all observed patterns. While a naïve approach may be to align the raw variables themselves (over time, for example, in the case of behavior, or as concatenated input to a model, in what is called \textbf{early integration}), there are several inherent problems that would need to be solved. For starters, different data modalities may rely on different hardware, with different collection rates, artifacts that would need to be removed, sensitivities, and overall limitations \cite{Jabeen2022ALearning}. This renders raw data alignment extremely hard, and forces researchers to often analyze modalities separately and draw joint conclusions manually. This separate processing is often called \textbf{late integration}, and while it solves many of the presented limitations, it carries the strong disadvantage of disregarding joint distributions across modalities, focusing exclusively on the marginals. When modalities are uncorrelated, however, this can be an extremely powerful framework, as illustrated by multimodal ensemble learning \cite{Ganaie2022EnsembleReview}.

Building on the previous section, the main focus of current approaches to multimodal integration deals with \textit{aligning data representations} (in what is known as \textbf{middle integration}) instead of the data themselves. By learning robust representations that extract features invariant to hardware noise and timescale nuances, these approaches hold the promise of having the best of both worlds: good alignment, while retaining and learning joint distributions. Thus and so, self-supervised approaches such as those presented in chapter~\ref{chap:methods} are showing promising results, since they allow several crucial levels of flexibility, such as having modality-specific encoders (which can deal with different types of data naturally), and specifically crafted contrastive positive and negative sampling schemes. Along these lines, the recently published package CEBRA \cite{Schneider2023LearnableAnalysis} offers a representation learning framework to learn joint embeddings using motion tracking and neural activity data with contrastive approaches. By aligning both modalities at the embedding level, CEBRA is capable of reporting non-linear neural correlates of motion, directly enabling questions regarding how one affects the other in complex ways that may be difficult to detect without computer assistance. Moreover, and in line with what was explored before in this section, two main positive and negative sampling schemes are provided: a purely unsupervised one, based on time alone and similar to that presented for DeepOF in chapter~\ref{chap:methods}, and a supervised one based on annotated labels. This makes it easier for researchers to choose between a more exploratory embedding of neural-motion interactions, or a hypothesis-driven one that can answer specific questions.

All in all, as both hardware and software technology advance, new methods are being developed that enable researchers to get a more holistic view of living organisms as systems, instead of independent collections of unrelated features. As time advances, I expect these approaches to become more prevalent and lead to better representations. While multimodal integration holds an exciting and extremely useful potential for research moving forward, however, motion tracking has the advantage of relying on relatively affordable hardware (video cameras) which enabled its wide adoption in the first place. It should thus not escape our attention that including more data modalities can be prohibitively hard, both in terms of labor intensity for data collection and elevated costs, especially in resource-constrained labs. This renders parallel efforts in representation learning on motion tracking data alone (such as DeepOF) extremely relevant too.

\section{Impact of the presented results in chronic stress research}

With the deeper understanding of the current status of behavioral analysis (and motion tracking in particular) built over the last few sections, we can now explore the impact of the presented research in our understanding of the model introduced as a case study: Chronic Social Defeat Stress.
As explored in chapters~\ref{chap:introduction} and \ref{chap:natcomm}, the individual and social behavior of animals exposed to CSDS has been extensively researched using models such as elevated plus mazes and social avoidance tasks, which can distinguish anxiety-like and altered social behaviors between cases and controls. This thesis has displayed several ways in which DeepOF has improved the state of the art in this regard, both reducing experimental effort and enabling greater analysis detail.

For starters, the observation that after exposure to the aggressive conspecific during the CSDS pipeline, experimental subjects' behavior follows an arousal pattern that fades over time due to habituation is, to the best of our knowledge, novel. The first relevant contribution of this thesis to CSDS research is then the supervised and unsupervised quantification of this arousal period, which in all our datasets was between two and two and a half minutes (and therefore close to the typical duration of a social avoidance task \cite{Kudryavtseva1991SocialStrain}). These results were moreover absent in single animal settings, which further supports this interpretation.

In line with these findings, our study showcases how the behavioral annotation provided within DeepOF leads to a more effective distinction of the social behavioral profile between stressed and non-stressed animals compared to the traditional SA task. This is a non-trivial finding: while capable of more detail, DeepOF is a general purpose tool, whereas the aforementioned task was specifically designed to detect this phenotype. I believe this is a great example of how overfitting specific measurements to our experimental designs may not always be optimal, and of how carefully tested exploratory tools can take us extremely far already.

Another result worth revisiting in this section is the differential entropy between stressed and non-stressed animals reported from our unsupervised pipeline. The fact that stressed animals display lower entropy in the discrete behaviors they explore is also non-trivial, and it highlights how reduced and focused on avoiding a potential stressor behavior becomes in stressful situations, arguably in line with the fight-or-flight response \cite{Chu2022PhysiologyReaction}.

Besides these specific contributions, DeepOF holds potential to explore in even more depth this model, such as for the identification of animals susceptible to stress and those resilient to it, which are often determined using oversimplified outcomes in the aforementioned social avoidance test, such as the fraction of time experimental animals spent close to their conspecific. While this variable (known in the literature as SA ratio) effectively distinguishes individuals affected by stress, especially in more severe CSDS conditions, our approach seems to significantly enhance the scope and sensitivity of this distinction, although more research is needed in this regard. Moreover, a tool included in DeepOF that was not put to use in this thesis and can work well in this context is the possibility to train control normative models. These work by fitting Gaussian kernel densities to the global animal embeddings of control animals, and reporting differences in the likelihood under the model between conditions. Stressed animals with embeddings that are closer to the control population could then be tagged as resilient. The next and final section on translational research applications will further explore this idea, showcasing its potential for more complex settings, such as the detection of the depression-like syndrome presented in chapter \ref{chap:introduction}.

In conclusion, the annotation pipelines implemented in DeepOF provide a more comprehensive and precise individual and social behavioral profile of animals exposed to CSDS when compared to the previous state of the art in the field. This has several implications moving forward, such as the potential adoption of DeepOF (or similar tools) for CSDS quantification as a standard procedure, and the deeper exploration of the tool for other aspects not discussed here. Moreover, an important factor contributing to the overall success of DeepOF in the presented social behavioral profiling lies in its experimental setup. While the social avoidance task relies on confined animals (typically in wired mesh cages, which prevent natural interaction between freely moving animals), open field settings allow for a much more natural interaction. Moreover, in the SA task, confined animals may display anxiety-related behaviors that influence their physiological state and their social interaction and approach behaviors with the conspecific.

Finally, and while we believe that our contributions to CSDS are significant and worth mentioning, we should not lose sight of the broader scope. Chronic stress is just one example setting in which such pipeline can be applied, and much more remains to be explored in other equivalent or more complex models. The next and final section will explore this in detail, focusing on how translational research can be positively affected with tools such as these.


\section{Frontiers of the field: between translational research and knowledge discovery}

As thoroughly explored in chapter \ref{chap:introduction}, the current state of research in applied neurobiology and psychiatry research lies far from the clinic. While many studies present innovations in drug development, genetic markers, and more, little is translated to real patients, in a phenomenon that has been described as the translational gap \cite{Shemesh2023ANeuroethology}. Moreover, despite animal models being adopted decades ago, their use to mimic mental disorders hasn’t managed to live up to the expectations. This is due to many reasons, such as the complexity of mental disorders per se and their prominent environmental causes, which are to date difficult to replicate in animals \cite{vonMucke-Heim2022IntroducingMice}. On top of this, and the lack of biologically-driven definitions of mental disorders makes the problem harder, as currently described entities could correspond to more than one etiologically relevant entity \cite{Miranda2021SystematicSubtyping}.

Even when taking all these issues into account, I believe there is light at the end of the tunnel, and that the potential of modern behavioral quantification in this regard is significant. Firstly, because it allows for finer-grain measurements that can be used to get more disentangled and data-driven definitions of the diseases under study, as seen with the RDoC initiative \cite{Vilar2019TranslationalRDoC}. Second, because once these definitions are agreed upon, this technology could simplify the accurate assignment of labels to subjects under study, decreasing the focus on more subjective measurements \cite{Miranda2021SystematicSubtyping}. Moreover, as seen with the depression-like syndrome introduced in chapter \ref{chap:introduction}, these disentangled definitions are key to improving back-translation \cite{vonMucke-Heim2022IntroducingMice}. That is, the definition of human-equivalent diseases in animal models that are as close as possible to the clinically relevant phenotype. In this regard, the normative modelling pipeline introduced in the previous section can play a key role: as a follow-up study to what was presented in chapter \ref{chap:natcomm}, we are currently using DeepOF to build domain specific normative models for DLS. This way, animals can be scored on each behavioral domain that escapes the species barrier (which are \textit{loss of energy and fatigue}, \textit{lack of concentration and indecisiveness}, \textit{psychomotor agitation or retardation}, \textit{disturbed sleep with hyper or hyposomnia}, \textit{apetite or weight changes}, and \textit{diminished interest or pleasure in activities}). By detecting shifts on each of these domains, many of which are carried out with DeepOF, we can get individual profiles for each experimental mouse. This way, DeepOF can be used in two stages, first to select individuals that meet stricter inclusion criteria for follow-up studies, and second to detect shifts in behavior upon applying a treatment (such as a drug).

Moreover, these technologies are not limited to animal models. Given that the ultimate goal of clinical research is to comprehend and enhance the quality of life for humans, assigning humans to the correct labels, and study their shifts in behavior systematically, is also crucial. In this context, advancements in comprehending human behavior through virtual reality (VR) are noteworthy. Presently, VR enables researchers to accurately monitor movement in meticulously designed settings, facilitating the transfer of paradigms like fear conditioning to human participants noninvasively \cite{Binder2022FacingPhobia, Rubio2023Auto-EncodersPerspectives}. Tools such as DeepOF can be applied to this type of data as well \cite{Sahili2023Spatio-TemporalSurvey}.

Finally, and while translation to the clinic is set as the final goal in this context, these technologies can also be of great help to acquire new knowledge. For example, the use of unsupervised learning in motion tracking data has the potential to uncover new behaviors that are systematically expressed in certain conditions, although more research in novel situations is needed in this regard \cite{Mathis2020APerspectives}. Moreover, detecting unsupervised shifts in behavior can be of great use in many high-throughput and hypothesis-free situations, such as Quantitative Trait Loci (QTL) mapping \cite{Abiola2003TheView}. This refers to a statistical method that aims to link two types of information, namely phenotypic data (quantitative traits, as behavior in this case) and genotypic data in the cohorts under study. This way, researchers can identify regions in the genome that can influence the variation of a given trait.

Even though in the context of DeepOF and similar tools these quantitative traits could be any measured parameter (such as speed, locomotion, social interactions, etc.), I believe the unsupervised animal embeddings introduced earlier are the most interesting opportunity in this regard. By detecting global shifts in behavior that are not associated with any particular hypothesis, researchers can increase throughput and scope massively. Moreover, detected shifts can then be analyzed individually, to dissect the differentially expressed patterns in a hypothesis-driven manner with the same tool. A similar idea is already being applied (although relying on supervised learning models detecting specific traits) for high-throughput drug discovery \cite{IndustrializingDiscovery}.

Linking together everything discussed in this section, DeepOF and similar tools are already being used today to revolutionize research in animal and human behavior, and hold increasing potential to have a positive impact on the current definitions of psychiatric conditions, improve pre-clinical and clinical trials, and aid relevant biological and drug discovery. The future of the field looks increasingly promising, and our contribution is but a grain of sand.